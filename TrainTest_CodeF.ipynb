{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TrainTest_Code.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cervantes-loves-ai/awesome-anomaly-detection/blob/master/TrainTest_CodeF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SZQZEr2W4nd",
        "colab_type": "code",
        "outputId": "2e5ec7d7-3206-40e3-81e6-848cc9dd4194",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bagzZBSYf4BE",
        "colab_type": "text"
      },
      "source": [
        "# Install dependencies\n",
        "Note: turn on GPU mode to start using CUDA, change runtime type to Python 3.\n",
        "\n",
        "1. Keras 1.1.0\n",
        "2. Theano 0.9.0\n",
        "3. By default, latest CUDA installed. Downgrade to CUDA 8.0 for compatible purpose, modify GCC version accordingly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4JBThiEtUZV",
        "colab_type": "code",
        "outputId": "0b916637-12f7-402f-92b5-40afd6b85729",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "!nvcc --version\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2018 NVIDIA Corporation\n",
            "Built on Sat_Aug_25_21:08:01_CDT_2018\n",
            "Cuda compilation tools, release 10.0, V10.0.130\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvJFkJo97q0q",
        "colab_type": "code",
        "outputId": "845a96d8-06e9-459c-b037-553958a3cc37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!sudo apt-get install python-yaml -y\n",
        "!sudo apt-get install libhdf5-serial-dev -y\n",
        "!sudo pip install keras==1.1.0\n",
        "!pip install theano==0.9.0\n",
        "!pip install path.py"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  python-yaml\n",
            "0 upgraded, 1 newly installed, 0 to remove and 8 not upgraded.\n",
            "Need to get 115 kB of archives.\n",
            "After this operation, 479 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-yaml amd64 3.12-1build2 [115 kB]\n",
            "Fetched 115 kB in 2s (71.2 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package python-yaml.\n",
            "(Reading database ... 131183 files and directories currently installed.)\n",
            "Preparing to unpack .../python-yaml_3.12-1build2_amd64.deb ...\n",
            "Unpacking python-yaml (3.12-1build2) ...\n",
            "Setting up python-yaml (3.12-1build2) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  libhdf5-serial-dev\n",
            "0 upgraded, 1 newly installed, 0 to remove and 8 not upgraded.\n",
            "Need to get 2,898 B of archives.\n",
            "After this operation, 37.9 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libhdf5-serial-dev all 1.10.0-patch1+docs-4 [2,898 B]\n",
            "Fetched 2,898 B in 1s (5,588 B/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libhdf5-serial-dev.\n",
            "(Reading database ... 131214 files and directories currently installed.)\n",
            "Preparing to unpack .../libhdf5-serial-dev_1.10.0-patch1+docs-4_all.deb ...\n",
            "Unpacking libhdf5-serial-dev (1.10.0-patch1+docs-4) ...\n",
            "Setting up libhdf5-serial-dev (1.10.0-patch1+docs-4) ...\n",
            "Collecting keras==1.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/5e/7e64f15f0e5ae65a29c738fc261ce1e0a72d92acfc45f06ef906c6e84bf2/Keras-1.1.0.tar.gz (150kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: theano in /usr/local/lib/python3.6/dist-packages (from keras==1.1.0) (1.0.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==1.1.0) (3.13)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from keras==1.1.0) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from theano->keras==1.1.0) (1.16.4)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from theano->keras==1.1.0) (1.3.1)\n",
            "Building wheels for collected packages: keras\n",
            "  Building wheel for keras (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras: filename=Keras-1.1.0-cp36-none-any.whl size=178686 sha256=f6cbcd27b6c933d30782fe38bfe2748517678e9490ed62989ae8bfce83239751\n",
            "  Stored in directory: /root/.cache/pip/wheels/ae/83/3e/c42ce0672e537640ee706143ebdd1dd691b7693b4ca50f72a8\n",
            "Successfully built keras\n",
            "\u001b[31mERROR: textgenrnn 1.4.1 has requirement keras>=2.1.5, but you'll have keras 1.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: kapre 0.1.3.1 has requirement keras>=2.0.0, but you'll have keras 1.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fancyimpute 0.4.3 has requirement keras>=2.0.0, but you'll have keras 1.1.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: keras\n",
            "  Found existing installation: Keras 2.2.5\n",
            "    Uninstalling Keras-2.2.5:\n",
            "      Successfully uninstalled Keras-2.2.5\n",
            "Successfully installed keras-1.1.0\n",
            "Collecting theano==0.9.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/28/03/6af9ff242da966f89de6ab81164db0d1a36fd89379b7370f07043de62f10/Theano-0.9.0.tar.gz (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from theano==0.9.0) (1.16.4)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from theano==0.9.0) (1.3.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from theano==0.9.0) (1.12.0)\n",
            "Building wheels for collected packages: theano\n",
            "  Building wheel for theano (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for theano: filename=Theano-0.9.0-cp36-none-any.whl size=2971676 sha256=5e5debd9963dcb9bd8cca11925aa0f941d7cad23dc526a4ccdb62a561c3c0036\n",
            "  Stored in directory: /root/.cache/pip/wheels/0e/fc/db/63f9bf0e2653f2fa69483040b060b0d8a5f264986e10750820\n",
            "Successfully built theano\n",
            "\u001b[31mERROR: pymc3 3.7 has requirement theano>=1.0.4, but you'll have theano 0.9.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: kapre 0.1.3.1 has requirement keras>=2.0.0, but you'll have keras 1.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fancyimpute 0.4.3 has requirement keras>=2.0.0, but you'll have keras 1.1.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: theano\n",
            "  Found existing installation: Theano 1.0.4\n",
            "    Uninstalling Theano-1.0.4:\n",
            "      Successfully uninstalled Theano-1.0.4\n",
            "Successfully installed theano-0.9.0\n",
            "Collecting path.py\n",
            "  Downloading https://files.pythonhosted.org/packages/40/62/1464f08672cac67e529967ba83b46f38da5d0ca48ac1ce2a9e7d7680ea10/path.py-12.0.1-py3-none-any.whl\n",
            "Requirement already satisfied: importlib-metadata>=0.5 in /usr/local/lib/python3.6/dist-packages (from path.py) (0.19)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.5->path.py) (0.6.0)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.6/dist-packages (from zipp>=0.5->importlib-metadata>=0.5->path.py) (7.2.0)\n",
            "Installing collected packages: path.py\n",
            "Successfully installed path.py-12.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCQalthhapyS",
        "colab_type": "code",
        "outputId": "8093d5f2-453a-4b92-fee5-b90dcd88aff6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        }
      },
      "source": [
        "!apt update -qq;\n",
        "!wget https://developer.nvidia.com/compute/cuda/8.0/Prod2/local_installers/cuda-repo-ubuntu1604-8-0-local-ga2_8.0.61-1_amd64-deb;\n",
        "!dpkg -i cuda-repo-ubuntu1604-8-0-local-ga2_8.0.61-1_amd64-deb;\n",
        "!apt-key add /var/cuda-repo-8-0-local-ga2/7fa2af80.pub;\n",
        "!apt-get update -qq;\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "52 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "--2019-09-06 08:56:59--  https://developer.nvidia.com/compute/cuda/8.0/Prod2/local_installers/cuda-repo-ubuntu1604-8-0-local-ga2_8.0.61-1_amd64-deb\n",
            "Resolving developer.nvidia.com (developer.nvidia.com)... 192.229.189.146\n",
            "Connecting to developer.nvidia.com (developer.nvidia.com)|192.229.189.146|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://developer.download.nvidia.com/compute/cuda/8.0/secure/Prod2/local_installers/cuda-repo-ubuntu1604-8-0-local-ga2_8.0.61-1_amd64.deb?hXBSyeEvzsCeHkRJLMTSkcRbFn9tQpLJf134r3RE2U4utmAiyH7oV3eMIaqH7-lTtX_ugyvKoPTNpavoep0lbXhY0gT-oWPojQqjKHGJYk3W0vqOTIvi47EX562VLIrESWRIu5asNwEGmSgopl7rJJJqElMa9wly3d3d7w91ZmQl-ACl7dWp7h9liCPSdbMq9_tX_vgDtwKOTqkgXMHIv_Zc1Q [following]\n",
            "--2019-09-06 08:57:00--  https://developer.download.nvidia.com/compute/cuda/8.0/secure/Prod2/local_installers/cuda-repo-ubuntu1604-8-0-local-ga2_8.0.61-1_amd64.deb?hXBSyeEvzsCeHkRJLMTSkcRbFn9tQpLJf134r3RE2U4utmAiyH7oV3eMIaqH7-lTtX_ugyvKoPTNpavoep0lbXhY0gT-oWPojQqjKHGJYk3W0vqOTIvi47EX562VLIrESWRIu5asNwEGmSgopl7rJJJqElMa9wly3d3d7w91ZmQl-ACl7dWp7h9liCPSdbMq9_tX_vgDtwKOTqkgXMHIv_Zc1Q\n",
            "Resolving developer.download.nvidia.com (developer.download.nvidia.com)... 192.229.232.112, 2606:2800:247:2063:46e:21d:825:102e\n",
            "Connecting to developer.download.nvidia.com (developer.download.nvidia.com)|192.229.232.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1913589814 (1.8G) [application/x-deb]\n",
            "Saving to: ‘cuda-repo-ubuntu1604-8-0-local-ga2_8.0.61-1_amd64-deb’\n",
            "\n",
            "cuda-repo-ubuntu160 100%[===================>]   1.78G   115MB/s    in 13s     \n",
            "\n",
            "2019-09-06 08:57:14 (136 MB/s) - ‘cuda-repo-ubuntu1604-8-0-local-ga2_8.0.61-1_amd64-deb’ saved [1913589814/1913589814]\n",
            "\n",
            "Selecting previously unselected package cuda-repo-ubuntu1604-8-0-local-ga2.\n",
            "(Reading database ... 131218 files and directories currently installed.)\n",
            "Preparing to unpack cuda-repo-ubuntu1604-8-0-local-ga2_8.0.61-1_amd64-deb ...\n",
            "Unpacking cuda-repo-ubuntu1604-8-0-local-ga2 (8.0.61-1) ...\n",
            "Setting up cuda-repo-ubuntu1604-8-0-local-ga2 (8.0.61-1) ...\n",
            "Warning: The postinst maintainerscript of the package cuda-repo-ubuntu1604-8-0-local-ga2\n",
            "Warning: seems to use apt-key (provided by apt) without depending on gnupg or gnupg2.\n",
            "Warning: This will BREAK in the future and should be fixed by the package maintainer(s).\n",
            "Note: Check first if apt-key functionality is needed at all - it probably isn't!\n",
            "Warning: apt-key should not be used in scripts (called from postinst maintainerscript of the package cuda-repo-ubuntu1604-8-0-local-ga2)\n",
            "OK\n",
            "OK\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNNVtS4uXnf9",
        "colab_type": "code",
        "outputId": "ef2f7bd2-145a-454a-e98d-fd8e4ad56f24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!apt install g++-5\n",
        "!update-alternatives --remove-all gcc \n",
        "!update-alternatives --remove-all g++\n",
        "\n",
        "!update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-5 20\n",
        "!update-alternatives --install /usr/bin/g++ g++ /usr/bin/g++-5 20\n",
        "\n",
        "!update-alternatives --install /usr/bin/cc cc /usr/bin/gcc 30\n",
        "!update-alternatives --set cc /usr/bin/gcc\n",
        "\n",
        "!update-alternatives --install /usr/bin/c++ c++ /usr/bin/g++ 30\n",
        "!update-alternatives --set c++ /usr/bin/g++\n",
        "\n",
        "!sudo apt install cuda-8.0;"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  cpp-5 gcc-5 gcc-5-base libasan2 libgcc-5-dev libisl15 libmpx0\n",
            "  libstdc++-5-dev\n",
            "Suggested packages:\n",
            "  gcc-5-locales g++-5-multilib gcc-5-doc libstdc++6-5-dbg gcc-5-multilib\n",
            "  libgcc1-dbg libgomp1-dbg libitm1-dbg libatomic1-dbg libasan2-dbg\n",
            "  liblsan0-dbg libtsan0-dbg libubsan0-dbg libcilkrts5-dbg libmpx0-dbg\n",
            "  libquadmath0-dbg libstdc++-5-doc\n",
            "The following NEW packages will be installed:\n",
            "  cpp-5 g++-5 gcc-5 gcc-5-base libasan2 libgcc-5-dev libisl15 libmpx0\n",
            "  libstdc++-5-dev\n",
            "0 upgraded, 9 newly installed, 0 to remove and 52 not upgraded.\n",
            "Need to get 29.1 MB of archives.\n",
            "After this operation, 100 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 gcc-5-base amd64 5.5.0-12ubuntu1 [17.1 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libisl15 amd64 0.18-4 [548 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 cpp-5 amd64 5.5.0-12ubuntu1 [7,785 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libasan2 amd64 5.5.0-12ubuntu1 [264 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libmpx0 amd64 5.5.0-12ubuntu1 [9,888 B]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libgcc-5-dev amd64 5.5.0-12ubuntu1 [2,224 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic/universe amd64 gcc-5 amd64 5.5.0-12ubuntu1 [8,357 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libstdc++-5-dev amd64 5.5.0-12ubuntu1 [1,415 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic/universe amd64 g++-5 amd64 5.5.0-12ubuntu1 [8,450 kB]\n",
            "Fetched 29.1 MB in 19s (1,561 kB/s)\n",
            "Selecting previously unselected package gcc-5-base:amd64.\n",
            "(Reading database ... 131312 files and directories currently installed.)\n",
            "Preparing to unpack .../0-gcc-5-base_5.5.0-12ubuntu1_amd64.deb ...\n",
            "Unpacking gcc-5-base:amd64 (5.5.0-12ubuntu1) ...\n",
            "Selecting previously unselected package libisl15:amd64.\n",
            "Preparing to unpack .../1-libisl15_0.18-4_amd64.deb ...\n",
            "Unpacking libisl15:amd64 (0.18-4) ...\n",
            "Selecting previously unselected package cpp-5.\n",
            "Preparing to unpack .../2-cpp-5_5.5.0-12ubuntu1_amd64.deb ...\n",
            "Unpacking cpp-5 (5.5.0-12ubuntu1) ...\n",
            "Selecting previously unselected package libasan2:amd64.\n",
            "Preparing to unpack .../3-libasan2_5.5.0-12ubuntu1_amd64.deb ...\n",
            "Unpacking libasan2:amd64 (5.5.0-12ubuntu1) ...\n",
            "Selecting previously unselected package libmpx0:amd64.\n",
            "Preparing to unpack .../4-libmpx0_5.5.0-12ubuntu1_amd64.deb ...\n",
            "Unpacking libmpx0:amd64 (5.5.0-12ubuntu1) ...\n",
            "Selecting previously unselected package libgcc-5-dev:amd64.\n",
            "Preparing to unpack .../5-libgcc-5-dev_5.5.0-12ubuntu1_amd64.deb ...\n",
            "Unpacking libgcc-5-dev:amd64 (5.5.0-12ubuntu1) ...\n",
            "Selecting previously unselected package gcc-5.\n",
            "Preparing to unpack .../6-gcc-5_5.5.0-12ubuntu1_amd64.deb ...\n",
            "Unpacking gcc-5 (5.5.0-12ubuntu1) ...\n",
            "Selecting previously unselected package libstdc++-5-dev:amd64.\n",
            "Preparing to unpack .../7-libstdc++-5-dev_5.5.0-12ubuntu1_amd64.deb ...\n",
            "Unpacking libstdc++-5-dev:amd64 (5.5.0-12ubuntu1) ...\n",
            "Selecting previously unselected package g++-5.\n",
            "Preparing to unpack .../8-g++-5_5.5.0-12ubuntu1_amd64.deb ...\n",
            "Unpacking g++-5 (5.5.0-12ubuntu1) ...\n",
            "Setting up libisl15:amd64 (0.18-4) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Setting up gcc-5-base:amd64 (5.5.0-12ubuntu1) ...\n",
            "Setting up libmpx0:amd64 (5.5.0-12ubuntu1) ...\n",
            "Setting up libasan2:amd64 (5.5.0-12ubuntu1) ...\n",
            "Setting up libgcc-5-dev:amd64 (5.5.0-12ubuntu1) ...\n",
            "Setting up cpp-5 (5.5.0-12ubuntu1) ...\n",
            "Setting up libstdc++-5-dev:amd64 (5.5.0-12ubuntu1) ...\n",
            "Setting up gcc-5 (5.5.0-12ubuntu1) ...\n",
            "Setting up g++-5 (5.5.0-12ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "update-alternatives: error: no alternatives for gcc\n",
            "update-alternatives: error: no alternatives for g++\n",
            "update-alternatives: using /usr/bin/gcc-5 to provide /usr/bin/gcc (gcc) in auto mode\n",
            "update-alternatives: using /usr/bin/g++-5 to provide /usr/bin/g++ (g++) in auto mode\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "Note, selecting 'cuda-8-0' for regex 'cuda-8.0'\n",
            "Note, selecting 'libcuda-8.0-1' for regex 'cuda-8.0'\n",
            "The following additional packages will be installed:\n",
            "  cuda-command-line-tools-8-0 cuda-core-8-0 cuda-cublas-8-0\n",
            "  cuda-cublas-dev-8-0 cuda-cudart-8-0 cuda-cudart-dev-8-0 cuda-cufft-8-0\n",
            "  cuda-cufft-dev-8-0 cuda-curand-8-0 cuda-curand-dev-8-0 cuda-cusolver-8-0\n",
            "  cuda-cusolver-dev-8-0 cuda-cusparse-8-0 cuda-cusparse-dev-8-0\n",
            "  cuda-demo-suite-8-0 cuda-documentation-8-0 cuda-driver-dev-8-0\n",
            "  cuda-license-8-0 cuda-misc-headers-8-0 cuda-npp-8-0 cuda-npp-dev-8-0\n",
            "  cuda-nvgraph-8-0 cuda-nvgraph-dev-8-0 cuda-nvml-dev-8-0 cuda-nvrtc-8-0\n",
            "  cuda-nvrtc-dev-8-0 cuda-runtime-8-0 cuda-samples-8-0 cuda-toolkit-8-0\n",
            "  cuda-visual-tools-8-0\n",
            "The following NEW packages will be installed:\n",
            "  cuda-8-0 cuda-command-line-tools-8-0 cuda-core-8-0 cuda-cublas-8-0\n",
            "  cuda-cublas-dev-8-0 cuda-cudart-8-0 cuda-cudart-dev-8-0 cuda-cufft-8-0\n",
            "  cuda-cufft-dev-8-0 cuda-curand-8-0 cuda-curand-dev-8-0 cuda-cusolver-8-0\n",
            "  cuda-cusolver-dev-8-0 cuda-cusparse-8-0 cuda-cusparse-dev-8-0\n",
            "  cuda-demo-suite-8-0 cuda-documentation-8-0 cuda-driver-dev-8-0\n",
            "  cuda-license-8-0 cuda-misc-headers-8-0 cuda-npp-8-0 cuda-npp-dev-8-0\n",
            "  cuda-nvgraph-8-0 cuda-nvgraph-dev-8-0 cuda-nvml-dev-8-0 cuda-nvrtc-8-0\n",
            "  cuda-nvrtc-dev-8-0 cuda-runtime-8-0 cuda-samples-8-0 cuda-toolkit-8-0\n",
            "  cuda-visual-tools-8-0\n",
            "0 upgraded, 31 newly installed, 0 to remove and 52 not upgraded.\n",
            "Need to get 0 B/1,312 MB of archives.\n",
            "After this operation, 2,079 MB of additional disk space will be used.\n",
            "Get:1 file:/var/cuda-repo-8-0-local-ga2  cuda-license-8-0 8.0.61-1 [27.6 kB]\n",
            "Get:2 file:/var/cuda-repo-8-0-local-ga2  cuda-misc-headers-8-0 8.0.61-1 [1,077 kB]\n",
            "Get:3 file:/var/cuda-repo-8-0-local-ga2  cuda-core-8-0 8.0.61-1 [20.0 MB]\n",
            "Get:4 file:/var/cuda-repo-8-0-local-ga2  cuda-cudart-8-0 8.0.61-1 [135 kB]\n",
            "Get:5 file:/var/cuda-repo-8-0-local-ga2  cuda-driver-dev-8-0 8.0.61-1 [14.1 kB]\n",
            "Get:6 file:/var/cuda-repo-8-0-local-ga2  cuda-cudart-dev-8-0 8.0.61-1 [1,071 kB]\n",
            "Get:7 file:/var/cuda-repo-8-0-local-ga2  cuda-command-line-tools-8-0 8.0.61-1 [26.1 MB]\n",
            "Get:8 file:/var/cuda-repo-8-0-local-ga2  cuda-nvrtc-8-0 8.0.61-1 [9,585 kB]\n",
            "Get:9 file:/var/cuda-repo-8-0-local-ga2  cuda-nvrtc-dev-8-0 8.0.61-1 [10.8 kB]\n",
            "Get:10 file:/var/cuda-repo-8-0-local-ga2  cuda-cusolver-8-0 8.0.61-1 [29.3 MB]\n",
            "Get:11 file:/var/cuda-repo-8-0-local-ga2  cuda-cusolver-dev-8-0 8.0.61-1 [6,816 kB]\n",
            "Get:12 file:/var/cuda-repo-8-0-local-ga2  cuda-cublas-8-0 8.0.61-1 [27.2 MB]\n",
            "Get:13 file:/var/cuda-repo-8-0-local-ga2  cuda-cublas-dev-8-0 8.0.61-1 [57.4 MB]\n",
            "Get:14 file:/var/cuda-repo-8-0-local-ga2  cuda-cufft-8-0 8.0.61-1 [117 MB]\n",
            "Get:15 file:/var/cuda-repo-8-0-local-ga2  cuda-cufft-dev-8-0 8.0.61-1 [94.8 MB]\n",
            "Get:16 file:/var/cuda-repo-8-0-local-ga2  cuda-curand-8-0 8.0.61-1 [43.7 MB]\n",
            "Get:17 file:/var/cuda-repo-8-0-local-ga2  cuda-curand-dev-8-0 8.0.61-1 [67.7 MB]\n",
            "Get:18 file:/var/cuda-repo-8-0-local-ga2  cuda-cusparse-8-0 8.0.61-1 [28.8 MB]\n",
            "Get:19 file:/var/cuda-repo-8-0-local-ga2  cuda-cusparse-dev-8-0 8.0.61-1 [29.6 MB]\n",
            "Get:20 file:/var/cuda-repo-8-0-local-ga2  cuda-npp-8-0 8.0.61-1 [157 MB]\n",
            "Get:21 file:/var/cuda-repo-8-0-local-ga2  cuda-npp-dev-8-0 8.0.61-1 [82.3 MB]\n",
            "Get:22 file:/var/cuda-repo-8-0-local-ga2  cuda-samples-8-0 8.0.61-1 [101 MB]\n",
            "Get:23 file:/var/cuda-repo-8-0-local-ga2  cuda-documentation-8-0 8.0.61-1 [113 MB]\n",
            "Get:24 file:/var/cuda-repo-8-0-local-ga2  cuda-nvml-dev-8-0 8.0.61-1 [48.4 kB]\n",
            "Get:25 file:/var/cuda-repo-8-0-local-ga2  cuda-nvgraph-8-0 8.0.61-1 [2,948 kB]\n",
            "Get:26 file:/var/cuda-repo-8-0-local-ga2  cuda-nvgraph-dev-8-0 8.0.61-1 [3,028 kB]\n",
            "Get:27 file:/var/cuda-repo-8-0-local-ga2  cuda-visual-tools-8-0 8.0.61-1 [286 MB]\n",
            "Get:28 file:/var/cuda-repo-8-0-local-ga2  cuda-toolkit-8-0 8.0.61-1 [2,892 B]\n",
            "Get:29 file:/var/cuda-repo-8-0-local-ga2  cuda-runtime-8-0 8.0.61-1 [2,574 B]\n",
            "Get:30 file:/var/cuda-repo-8-0-local-ga2  cuda-demo-suite-8-0 8.0.61-1 [4,988 kB]\n",
            "Get:31 file:/var/cuda-repo-8-0-local-ga2  cuda-8-0 8.0.61-1 [2,556 B]\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 31.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package cuda-license-8-0.\n",
            "(Reading database ... 132312 files and directories currently installed.)\n",
            "Preparing to unpack .../00-cuda-license-8-0_8.0.61-1_amd64.deb ...\n",
            "Unpacking cuda-license-8-0 (8.0.61-1) ...\n",
            "Selecting previously unselected package cuda-misc-headers-8-0.\n",
            "Preparing to unpack .../01-cuda-misc-headers-8-0_8.0.61-1_amd64.deb ...\n",
            "Unpacking cuda-misc-headers-8-0 (8.0.61-1) ...\n",
            "Selecting previously unselected package cuda-core-8-0.\n",
            "Preparing to unpack .../02-cuda-core-8-0_8.0.61-1_amd64.deb ...\n",
            "Unpacking cuda-core-8-0 (8.0.61-1) ...\n",
            "Selecting previously unselected package cuda-cudart-8-0.\n",
            "Preparing to unpack .../03-cuda-cudart-8-0_8.0.61-1_amd64.deb ...\n",
            "Unpacking cuda-cudart-8-0 (8.0.61-1) ...\n",
            "Selecting previously unselected package cuda-driver-dev-8-0.\n",
            "Preparing to unpack .../04-cuda-driver-dev-8-0_8.0.61-1_amd64.deb ...\n",
            "Unpacking cuda-driver-dev-8-0 (8.0.61-1) ...\n",
            "Selecting previously unselected package cuda-cudart-dev-8-0.\n",
            "Preparing to unpack .../05-cuda-cudart-dev-8-0_8.0.61-1_amd64.deb ...\n",
            "Unpacking cuda-cudart-dev-8-0 (8.0.61-1) ...\n",
            "Selecting previously unselected package cuda-command-line-tools-8-0.\n",
            "Preparing to unpack .../06-cuda-command-line-tools-8-0_8.0.61-1_amd64.deb ...\n",
            "Unpacking cuda-command-line-tools-8-0 (8.0.61-1) ...\n",
            "Selecting previously unselected package cuda-nvrtc-8-0.\n",
            "Preparing to unpack .../07-cuda-nvrtc-8-0_8.0.61-1_amd64.deb ...\n",
            "Unpacking cuda-nvrtc-8-0 (8.0.61-1) ...\n",
            "Selecting previously unselected package cuda-nvrtc-dev-8-0.\n",
            "Preparing to unpack .../08-cuda-nvrtc-dev-8-0_8.0.61-1_amd64.deb ...\n",
            "Unpacking cuda-nvrtc-dev-8-0 (8.0.61-1) ...\n",
            "Selecting previously unselected package cuda-cusolver-8-0.\n",
            "Preparing to unpack .../09-cuda-cusolver-8-0_8.0.61-1_amd64.deb ...\n",
            "Unpacking cuda-cusolver-8-0 (8.0.61-1) ...\n",
            "Selecting previously unselected package cuda-cusolver-dev-8-0.\n",
            "Preparing to unpack .../10-cuda-cusolver-dev-8-0_8.0.61-1_amd64.deb ...\n",
            "Unpacking cuda-cusolver-dev-8-0 (8.0.61-1) ...\n",
            "Selecting previously unselected package cuda-cublas-8-0.\n",
            "Preparing to unpack .../11-cuda-cublas-8-0_8.0.61-1_amd64.deb ...\n",
            "Unpacking cuda-cublas-8-0 (8.0.61-1) ...\n",
            "Selecting previously unselected package cuda-cublas-dev-8-0.\n",
            "Preparing to unpack .../12-cuda-cublas-dev-8-0_8.0.61-1_amd64.deb ...\n",
            "Unpacking cuda-cublas-dev-8-0 (8.0.61-1) ...\n",
            "Selecting previously unselected package cuda-cufft-8-0.\n",
            "Preparing to unpack .../13-cuda-cufft-8-0_8.0.61-1_amd64.deb ...\n",
            "Unpacking cuda-cufft-8-0 (8.0.61-1) ...\n",
            "Selecting previously unselected package cuda-cufft-dev-8-0.\n",
            "Preparing to unpack .../14-cuda-cufft-dev-8-0_8.0.61-1_amd64.deb ...\n",
            "Unpacking cuda-cufft-dev-8-0 (8.0.61-1) ...\n",
            "Selecting previously unselected package cuda-curand-8-0.\n",
            "Preparing to unpack .../15-cuda-curand-8-0_8.0.61-1_amd64.deb ...\n",
            "Unpacking cuda-curand-8-0 (8.0.61-1) ...\n",
            "Selecting previously unselected package cuda-curand-dev-8-0.\n",
            "Preparing to unpack .../16-cuda-curand-dev-8-0_8.0.61-1_amd64.deb ...\n",
            "Unpacking cuda-curand-dev-8-0 (8.0.61-1) ...\n",
            "Selecting previously unselected package cuda-cusparse-8-0.\n",
            "Preparing to unpack .../17-cuda-cusparse-8-0_8.0.61-1_amd64.deb ...\n",
            "Unpacking cuda-cusparse-8-0 (8.0.61-1) ...\n",
            "Selecting previously unselected package cuda-cusparse-dev-8-0.\n",
            "Preparing to unpack .../18-cuda-cusparse-dev-8-0_8.0.61-1_amd64.deb ...\n",
            "Unpacking cuda-cusparse-dev-8-0 (8.0.61-1) ...\n",
            "Selecting previously unselected package cuda-npp-8-0.\n",
            "Preparing to unpack .../19-cuda-npp-8-0_8.0.61-1_amd64.deb ...\n",
            "Unpacking cuda-npp-8-0 (8.0.61-1) ...\n",
            "Selecting previously unselected package cuda-npp-dev-8-0.\n",
            "Preparing to unpack .../20-cuda-npp-dev-8-0_8.0.61-1_amd64.deb ...\n",
            "Unpacking cuda-npp-dev-8-0 (8.0.61-1) ...\n",
            "Selecting previously unselected package cuda-samples-8-0.\n",
            "Preparing to unpack .../21-cuda-samples-8-0_8.0.61-1_amd64.deb ...\n",
            "Unpacking cuda-samples-8-0 (8.0.61-1) ...\n",
            "Selecting previously unselected package cuda-documentation-8-0.\n",
            "Preparing to unpack .../22-cuda-documentation-8-0_8.0.61-1_amd64.deb ...\n",
            "Unpacking cuda-documentation-8-0 (8.0.61-1) ...\n",
            "Selecting previously unselected package cuda-nvml-dev-8-0.\n",
            "Preparing to unpack .../23-cuda-nvml-dev-8-0_8.0.61-1_amd64.deb ...\n",
            "Unpacking cuda-nvml-dev-8-0 (8.0.61-1) ...\n",
            "Selecting previously unselected package cuda-nvgraph-8-0.\n",
            "Preparing to unpack .../24-cuda-nvgraph-8-0_8.0.61-1_amd64.deb ...\n",
            "Unpacking cuda-nvgraph-8-0 (8.0.61-1) ...\n",
            "Selecting previously unselected package cuda-nvgraph-dev-8-0.\n",
            "Preparing to unpack .../25-cuda-nvgraph-dev-8-0_8.0.61-1_amd64.deb ...\n",
            "Unpacking cuda-nvgraph-dev-8-0 (8.0.61-1) ...\n",
            "Selecting previously unselected package cuda-visual-tools-8-0.\n",
            "Preparing to unpack .../26-cuda-visual-tools-8-0_8.0.61-1_amd64.deb ...\n",
            "Unpacking cuda-visual-tools-8-0 (8.0.61-1) ...\n",
            "Selecting previously unselected package cuda-toolkit-8-0.\n",
            "Preparing to unpack .../27-cuda-toolkit-8-0_8.0.61-1_amd64.deb ...\n",
            "Unpacking cuda-toolkit-8-0 (8.0.61-1) ...\n",
            "Selecting previously unselected package cuda-runtime-8-0.\n",
            "Preparing to unpack .../28-cuda-runtime-8-0_8.0.61-1_amd64.deb ...\n",
            "Unpacking cuda-runtime-8-0 (8.0.61-1) ...\n",
            "Selecting previously unselected package cuda-demo-suite-8-0.\n",
            "Preparing to unpack .../29-cuda-demo-suite-8-0_8.0.61-1_amd64.deb ...\n",
            "Unpacking cuda-demo-suite-8-0 (8.0.61-1) ...\n",
            "Selecting previously unselected package cuda-8-0.\n",
            "Preparing to unpack .../30-cuda-8-0_8.0.61-1_amd64.deb ...\n",
            "Unpacking cuda-8-0 (8.0.61-1) ...\n",
            "Setting up cuda-license-8-0 (8.0.61-1) ...\n",
            "*** LICENSE AGREEMENT ***\n",
            "By using this software you agree to fully comply with the terms and \n",
            "conditions of the EULA (End User License Agreement). The EULA is located\n",
            "at /usr/local/cuda-8.0/doc/EULA.txt. The EULA can also be found at\n",
            "http://docs.nvidia.com/cuda/eula/index.html. If you do not agree to the\n",
            "terms and conditions of the EULA, do not use the software.\n",
            "\n",
            "Setting up cuda-nvgraph-8-0 (8.0.61-1) ...\n",
            "Setting up cuda-cufft-8-0 (8.0.61-1) ...\n",
            "Setting up cuda-npp-8-0 (8.0.61-1) ...\n",
            "Setting up cuda-nvgraph-dev-8-0 (8.0.61-1) ...\n",
            "Setting up cuda-cudart-8-0 (8.0.61-1) ...\n",
            "Setting up cuda-driver-dev-8-0 (8.0.61-1) ...\n",
            "Setting up cuda-cusolver-8-0 (8.0.61-1) ...\n",
            "Setting up cuda-nvml-dev-8-0 (8.0.61-1) ...\n",
            "Setting up cuda-cufft-dev-8-0 (8.0.61-1) ...\n",
            "Setting up cuda-misc-headers-8-0 (8.0.61-1) ...\n",
            "Setting up cuda-cusparse-8-0 (8.0.61-1) ...\n",
            "Setting up cuda-nvrtc-8-0 (8.0.61-1) ...\n",
            "Setting up cuda-nvrtc-dev-8-0 (8.0.61-1) ...\n",
            "Setting up cuda-curand-8-0 (8.0.61-1) ...\n",
            "Setting up cuda-cublas-8-0 (8.0.61-1) ...\n",
            "Setting up cuda-cusolver-dev-8-0 (8.0.61-1) ...\n",
            "Setting up cuda-core-8-0 (8.0.61-1) ...\n",
            "Setting up cuda-curand-dev-8-0 (8.0.61-1) ...\n",
            "Setting up cuda-npp-dev-8-0 (8.0.61-1) ...\n",
            "Setting up cuda-cudart-dev-8-0 (8.0.61-1) ...\n",
            "Setting up cuda-cublas-dev-8-0 (8.0.61-1) ...\n",
            "Setting up cuda-runtime-8-0 (8.0.61-1) ...\n",
            "Setting up cuda-cusparse-dev-8-0 (8.0.61-1) ...\n",
            "Setting up cuda-command-line-tools-8-0 (8.0.61-1) ...\n",
            "Setting up cuda-demo-suite-8-0 (8.0.61-1) ...\n",
            "Setting up cuda-samples-8-0 (8.0.61-1) ...\n",
            "Setting up cuda-visual-tools-8-0 (8.0.61-1) ...\n",
            "Setting up cuda-documentation-8-0 (8.0.61-1) ...\n",
            "Setting up cuda-toolkit-8-0 (8.0.61-1) ...\n",
            "Setting up cuda-8-0 (8.0.61-1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EEXt-ThxffKy",
        "colab_type": "text"
      },
      "source": [
        "**cuDNN (v5.1):  a GPU-accelerated library of primitives for deep neural networks**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSDm_SkvXW6t",
        "colab_type": "code",
        "outputId": "3cbe954a-a08a-4300-c853-d3057a21a0a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        }
      },
      "source": [
        "%cd /content\n",
        "!wget http://developer.download.nvidia.com/compute/redist/cudnn/v5.1/cudnn-8.0-linux-x64-v5.1.tgz\n",
        "!tar -xzvf cudnn-8.0-linux-x64-v5.1.tgz\n",
        "!sudo cp -P cuda/include/cudnn.h /usr/local/cuda-8.0/include\n",
        "!sudo cp -P cuda/lib64/libcudnn* /usr/local/cuda-8.0/lib64/\n",
        "!sudo chmod a+r /usr/local/cuda-8.0/lib64/libcudnn*"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "--2019-09-06 08:59:57--  http://developer.download.nvidia.com/compute/redist/cudnn/v5.1/cudnn-8.0-linux-x64-v5.1.tgz\n",
            "Resolving developer.download.nvidia.com (developer.download.nvidia.com)... 192.229.232.112, 2606:2800:247:2063:46e:21d:825:102e\n",
            "Connecting to developer.download.nvidia.com (developer.download.nvidia.com)|192.229.232.112|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 103174002 (98M) [application/x-compressed]\n",
            "Saving to: ‘cudnn-8.0-linux-x64-v5.1.tgz’\n",
            "\n",
            "cudnn-8.0-linux-x64 100%[===================>]  98.39M   194MB/s    in 0.5s    \n",
            "\n",
            "2019-09-06 08:59:58 (194 MB/s) - ‘cudnn-8.0-linux-x64-v5.1.tgz’ saved [103174002/103174002]\n",
            "\n",
            "cuda/include/cudnn.h\n",
            "cuda/lib64/libcudnn.so\n",
            "cuda/lib64/libcudnn.so.5\n",
            "cuda/lib64/libcudnn.so.5.1.10\n",
            "cuda/lib64/libcudnn_static.a\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swM5Oy6FNF76",
        "colab_type": "code",
        "outputId": "267cc852-9477-4f7b-fa17-96ee352310e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        }
      },
      "source": [
        "!gcc --version\n",
        "!nvcc -V"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gcc (Ubuntu 5.5.0-12ubuntu1) 5.5.0 20171010\n",
            "Copyright (C) 2015 Free Software Foundation, Inc.\n",
            "This is free software; see the source for copying conditions.  There is NO\n",
            "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
            "\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2016 NVIDIA Corporation\n",
            "Built on Tue_Jan_10_13:22:03_CST_2017\n",
            "Cuda compilation tools, release 8.0, V8.0.61\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oebz5Db-6CY7",
        "colab_type": "code",
        "outputId": "71903918-095b-47c0-d3f1-cecab94118d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Sep  6 09:01:41 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 430.40       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P8    27W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFgJUD1zWatO",
        "colab_type": "code",
        "outputId": "e40d4054-9534-4e37-cf0f-00ddc071f925",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        }
      },
      "source": [
        "!pip install numpy==1.14.6 # downgrade to match the Theano version (if needed)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting numpy==1.14.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/c4/395ebb218053ba44d64935b3729bc88241ec279915e72100c5979db10945/numpy-1.14.6-cp36-cp36m-manylinux1_x86_64.whl (13.8MB)\n",
            "\u001b[K     |████████████████████████████████| 13.8MB 2.7MB/s \n",
            "\u001b[31mERROR: spacy 2.1.8 has requirement numpy>=1.15.0, but you'll have numpy 1.14.6 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: pymc3 3.7 has requirement theano>=1.0.4, but you'll have theano 0.9.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: kapre 0.1.3.1 has requirement keras>=2.0.0, but you'll have keras 1.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: imgaug 0.2.9 has requirement numpy>=1.15.0, but you'll have numpy 1.14.6 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fastai 1.0.57 has requirement numpy>=1.15, but you'll have numpy 1.14.6 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fancyimpute 0.4.3 has requirement keras>=2.0.0, but you'll have keras 1.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: cvxpy 1.0.25 has requirement numpy>=1.15, but you'll have numpy 1.14.6 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: blis 0.2.4 has requirement numpy>=1.15.0, but you'll have numpy 1.14.6 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Found existing installation: numpy 1.16.4\n",
            "    Uninstalling numpy-1.16.4:\n",
            "      Successfully uninstalled numpy-1.16.4\n",
            "Successfully installed numpy-1.14.6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEqbn65t0eJI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "outputId": "419a887e-feb9-4793-e163-8ff7e8e621fd"
      },
      "source": [
        "!pip install -U numpy "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting numpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/92/57179ed45307ec6179e344231c47da7f3f3da9e2eee5c8ab506bd279ce4e/numpy-1.17.1-cp36-cp36m-manylinux1_x86_64.whl (20.4MB)\n",
            "\u001b[K     |████████████████████████████████| 20.4MB 2.8MB/s \n",
            "\u001b[31mERROR: pymc3 3.7 has requirement theano>=1.0.4, but you'll have theano 0.9.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: kapre 0.1.3.1 has requirement keras>=2.0.0, but you'll have keras 1.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fancyimpute 0.4.3 has requirement keras>=2.0.0, but you'll have keras 1.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Found existing installation: numpy 1.14.6\n",
            "    Uninstalling numpy-1.14.6:\n",
            "      Successfully uninstalled numpy-1.14.6\n",
            "Successfully installed numpy-1.17.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiH-kHVwUmn_",
        "colab_type": "text"
      },
      "source": [
        "#Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aF_O3F8DKRJa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ[\"THEANO_FLAGS\"] = \"mode=FAST_RUN,device=gpu0,floatX=float32\"\n",
        "os.environ[\"KERAS_BACKEND\"] = \"theano\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "McFibqbemQR6",
        "colab_type": "code",
        "outputId": "f11f8301-24ce-4777-c211-2ef2440d2353",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!pip install nose\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nose in /usr/local/lib/python3.6/dist-packages (1.3.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mrErt_G5MqR",
        "colab_type": "code",
        "outputId": "e33c43a0-e86b-451d-c33b-6419f073c156",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, TimeDistributedDense ,LSTM,Reshape\n",
        "from keras.regularizers import l2\n",
        "from keras.optimizers import SGD,adam, Adagrad\n",
        "from scipy.io import loadmat, savemat\n",
        "from keras.models import model_from_json\n",
        "import theano.tensor as T\n",
        "import theano\n",
        "import csv\n",
        "import configparser\n",
        "import collections\n",
        "import time\n",
        "import csv\n",
        "import os\n",
        "from os import listdir\n",
        "import skimage.transform\n",
        "from skimage import color\n",
        "from os.path import isfile, join\n",
        "import numpy as np\n",
        "import numpy\n",
        "from datetime import datetime\n",
        "import path\n",
        "from os.path import basename\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import theano.sandbox\n",
        "theano.sandbox.cuda.use('gpu0')\n",
        "from IPython.display import clear_output\n",
        "import math"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
            " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AgAlbvLnrCR",
        "colab_type": "text"
      },
      "source": [
        "**3 FC Layers**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJ3IOx5IRXDv",
        "colab_type": "code",
        "outputId": "878d1605-975c-4c94-accd-02ea6554ef01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        }
      },
      "source": [
        "print(\"Create Model\")\n",
        "model = Sequential()\n",
        "model.add(Dense(512, input_dim=4096,init='glorot_normal',W_regularizer=l2(0.001),activation='relu'))\n",
        "model.add(Dropout(0.6))\n",
        "model.add(Dense(32,init='glorot_normal',W_regularizer=l2(0.001)))\n",
        "model.add(Dropout(0.6))\n",
        "model.add(Dense(1,init='glorot_normal',W_regularizer=l2(0.001),activation='sigmoid'))\n",
        "print(model.summary())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Create Model\n",
            "____________________________________________________________________________________________________\n",
            "Layer (type)                     Output Shape          Param #     Connected to                     \n",
            "====================================================================================================\n",
            "dense_1 (Dense)                  (None, 512)           2097664     dense_input_1[0][0]              \n",
            "____________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)              (None, 512)           0           dense_1[0][0]                    \n",
            "____________________________________________________________________________________________________\n",
            "dense_2 (Dense)                  (None, 32)            16416       dropout_1[0][0]                  \n",
            "____________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)              (None, 32)            0           dense_2[0][0]                    \n",
            "____________________________________________________________________________________________________\n",
            "dense_3 (Dense)                  (None, 1)             33          dropout_2[0][0]                  \n",
            "====================================================================================================\n",
            "Total params: 2114113\n",
            "____________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqebxtGM5dV9",
        "colab_type": "code",
        "outputId": "3e1f7e27-e468-4085-bcba-885272051667",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# COUNT THE NUMBER OF VIDEO\n",
        "!ls -l \"/content/gdrive/My Drive/Colab Notebooks/mydrive/Train_RoadAccidents/Normal\" | egrep -c '^-'\n",
        "!ls -l \"/content/gdrive/My Drive/Colab Notebooks/mydrive/Train_RoadAccidents/Abnormal\" | egrep -c '^-'\n",
        "!ls -l \"/content/gdrive/My Drive/Colab Notebooks/mydrive/Train_RoadAccidents/Test_RoadAccidents\" | egrep -c '^-'"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "111\n",
            "24\n",
            "15\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6G7ePd1Wl67",
        "colab_type": "text"
      },
      "source": [
        "# Load and label video (0/1), implement objective function\n",
        "\n",
        "1.   Utility functions: load/save model/weight, load video feature and make label (0/1) in batch size of 60.\n",
        "2.   Objective function\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugLuD5rsRYeD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_model(json_path):\n",
        "    model = model_from_json(open(json_path).read())\n",
        "    return model\n",
        "\n",
        "def load_weights(model, weight_path): # Function to load the model weights\n",
        "    dict2 = loadmat(weight_path)\n",
        "    dict = conv_dict(dict2)\n",
        "    i = 0\n",
        "    for layer in model.layers:\n",
        "        weights = dict[str(i)]\n",
        "        layer.set_weights(weights)\n",
        "        i += 1\n",
        "    return model\n",
        "\n",
        "def conv_dict(dict2):\n",
        "    i = 0\n",
        "    dict = {}\n",
        "    for i in range(len(dict2)):\n",
        "        if str(i) in dict2:\n",
        "            if dict2[str(i)].shape == (0, 0):\n",
        "                dict[str(i)] = dict2[str(i)]\n",
        "            else:\n",
        "                weights = dict2[str(i)][0]\n",
        "                weights2 = []\n",
        "                for weight in weights:\n",
        "                    if weight.shape in [(1, x) for x in range(0, 5000)]:\n",
        "                        weights2.append(weight[0])\n",
        "                    else:\n",
        "                        weights2.append(weight)\n",
        "                dict[str(i)] = weights2\n",
        "    return dict\n",
        "\n",
        "def save_model(model, json_path, weight_path):\n",
        "    json_string = model.to_json()\n",
        "    open(json_path, 'w').write(json_string)\n",
        "    dict = {}\n",
        "    i = 0\n",
        "    for layer in model.layers:\n",
        "        weights = layer.get_weights()\n",
        "        my_list = np.zeros(len(weights), dtype=np.object)\n",
        "        my_list[:] = weights\n",
        "        dict[str(i)] = my_list\n",
        "        i += 1\n",
        "    savemat(weight_path, dict)\n",
        "\n",
        "\n",
        "# Load Training Dataset and label training videos\n",
        "\n",
        "def load_dataset_Train_batch(AbnormalPath, NormalPath):\n",
        "\n",
        "    batchsize=60            # Each batch contain 60 videos.\n",
        "    n_exp=int(batchsize/2)  # 30 normal and 30 road accident videos\n",
        "\n",
        "    Num_abnormal = 366  # number of road accident videos in Training set.\n",
        "    Num_Normal = 330    # number of normal videos in Training set.\n",
        "\n",
        "\n",
        "    # We assume the features of abnormal videos and normal videos are located in two different folders.\n",
        "    Abnor_list_iter = np.random.permutation(Num_abnormal)\n",
        "    Abnor_list_iter = Abnor_list_iter[Num_abnormal-n_exp:] # Indexes for randomly selected Abnormal Videos\n",
        "    Norm_list_iter = np.random.permutation(Num_Normal)\n",
        "    Norm_list_iter = Norm_list_iter[Num_Normal-n_exp:]     # Indexes for randomly selected Normal Videos\n",
        "\n",
        "    AllVideos_Path = AbnormalPath\n",
        "    def listdir_nohidden(AllVideos_Path):  # To ignore hidden files\n",
        "        file_dir_extension = os.path.join(AllVideos_Path, '*_C.txt')\n",
        "        for f in glob.glob(file_dir_extension):\n",
        "            if not f.startswith('.'):\n",
        "                yield os.path.basename(f)\n",
        "\n",
        "    All_Videos=sorted(listdir_nohidden(AllVideos_Path))\n",
        "    All_Videos.sort()\n",
        "    AllFeatures = []  # To store C3D features of a batch\n",
        "    print(\"Loading Abnormal videos Features...\")\n",
        "\n",
        "    Video_count=-1\n",
        "    \n",
        "    ###################### READ RANDOMLY ABNORMAL FEATURE 32x4096 #################\n",
        "    for iv in Abnor_list_iter:\n",
        "        Video_count=Video_count+1\n",
        "        VideoPath = os.path.join(AllVideos_Path, All_Videos[iv])\n",
        "        f = open(VideoPath, \"r\")\n",
        "        words = f.read().split()\n",
        "        num_feat = int(len(words) / 4096)\n",
        "        # Number of features per video to be loaded.\n",
        "        # In our case num_feat=32, as we divide the video into 32 segments. \n",
        "\n",
        "        count = -1;\n",
        "        VideoFeatues = []\n",
        "        for feat in range(0, num_feat):\n",
        "            feat_row1 = np.float32(words[feat * 4096:feat * 4096 + 4096])\n",
        "            count = count + 1\n",
        "            if count == 0:\n",
        "                VideoFeatues = feat_row1\n",
        "            if count > 0:\n",
        "                VideoFeatues = np.vstack((VideoFeatues, feat_row1))\n",
        "\n",
        "        if Video_count == 0:\n",
        "            AllFeatures = VideoFeatues\n",
        "        if Video_count > 0:\n",
        "            AllFeatures = np.vstack((AllFeatures, VideoFeatues))\n",
        "\n",
        "        \n",
        "        \n",
        "    print(\"Loading Normal videos...\")\n",
        "    AllVideos_Path =  NormalPath\n",
        "\n",
        "    def listdir_nohidden(AllVideos_Path):  # To ignore hidden files\n",
        "        file_dir_extension = os.path.join(AllVideos_Path, '*_C.txt')\n",
        "        for f in glob.glob(file_dir_extension):\n",
        "            if not f.startswith('.'):\n",
        "                yield os.path.basename(f)\n",
        "\n",
        "    All_Videos = sorted(listdir_nohidden(AllVideos_Path))\n",
        "    All_Videos.sort()\n",
        "\n",
        "    for iv in Norm_list_iter:\n",
        "        VideoPath = os.path.join(AllVideos_Path, All_Videos[iv])\n",
        "        f = open(VideoPath, \"r\")\n",
        "        words = f.read().split()\n",
        "        feat_row1 = np.array([])\n",
        "        num_feat = int(len(words) /4096)   \n",
        "        # Number of features to be loaded. \n",
        "        # In our case num_feat=32, as we divide the video into 32 segments.\n",
        "\n",
        "        count = -1;\n",
        "        VideoFeatues = []\n",
        "        for feat in range(0, num_feat):\n",
        "\n",
        "\n",
        "            feat_row1 = np.float32(words[feat * 4096:feat * 4096 + 4096])\n",
        "            count = count + 1\n",
        "            if count == 0:\n",
        "                VideoFeatues = feat_row1\n",
        "            if count > 0:\n",
        "                VideoFeatues = np.vstack((VideoFeatues, feat_row1))\n",
        "            feat_row1 = []\n",
        "        AllFeatures = np.vstack((AllFeatures, VideoFeatues))\n",
        "\n",
        "    print(\"Features  loaded\")\n",
        "\n",
        "\n",
        "    AllLabels = np.zeros(32*batchsize, dtype='uint8') \n",
        "    # 60*32 = 1920 label, 0/1 (INTEGER, please remember, regression init)\n",
        "    \n",
        "    th_loop1=n_exp*32\n",
        "    th_loop2=n_exp*32-1\n",
        "    \n",
        "    # mini-batch size = 60, 30 normals, 30 abnormals\n",
        "    # --> 30*32= 640 feature vectors for 32 segments and 30 videos\n",
        "\n",
        "\n",
        "    # Load Abnormal path fist--> index 0-639 is assigned value 0,\n",
        "    # remains 640 from th_loop2 = 640-1920 to label 1\n",
        "    \n",
        "    for iv in range(0, 32*batchsize): # 1920\n",
        "            if iv< th_loop1:\n",
        "                AllLabels[iv] = int(0)  # All instances of abnormal videos are labeled 0.  This will be used in custom_objective to keep track of normal and abnormal videos indexes.\n",
        "            if iv > th_loop2:\n",
        "                AllLabels[iv] = int(1)   # All instances of Normal videos are labeled 1. This will be used in custom_objective to keep track of normal and abnormal videos indexes.\n",
        "\n",
        "          # There are 1920 labels in total (all instances 32segment*60video a batch)\n",
        "          \n",
        "    return  AllFeatures,AllLabels\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ub8Gd8QYn3sY",
        "colab_type": "text"
      },
      "source": [
        "**Objective function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQnCfdcDn3KV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def custom_objective(y_true, y_pred):\n",
        "  \n",
        "    y_true = T.flatten(y_true)\n",
        "    y_pred = T.flatten(y_pred)\n",
        "    n_seg = 32  \n",
        "    nvid = 60\n",
        "    n_exp = int(nvid / 2)\n",
        "    Num_d=32*nvid\n",
        "\n",
        "\n",
        "    sub_max = T.ones_like(y_pred) # sub_max represents the highest scoring instants in bags (videos).\n",
        "    sub_sum_labels = T.ones_like(y_true) # It is used to sum the labels in order to distinguish between normal and abnormal videos.\n",
        "    sub_sum_l1=T.ones_like(y_true)  # For holding the concatenation of summation of scores in the bag.\n",
        "    sub_l2 = T.ones_like(y_true) # For holding the concatenation of L2 of score in the bag.\n",
        "    \n",
        "    \n",
        "    for ii in range(0, nvid, 1):\n",
        "        # For Labels\n",
        "        mm = y_true[ii * n_seg:ii * n_seg + n_seg]\n",
        "        sub_sum_labels = T.concatenate([sub_sum_labels, T.stack(T.sum(mm))])  # Just to keep track of abnormal and normal vidoes\n",
        "        \n",
        "        # For Features scores\n",
        "        Feat_Score = y_pred[ii * n_seg:ii * n_seg + n_seg]\n",
        "        sub_max = T.concatenate([sub_max, T.stack(T.max(Feat_Score))])         # Keep the maximum score of scores of all instances in a Bag (video)\n",
        "        sub_sum_l1 = T.concatenate([sub_sum_l1, T.stack(T.sum(Feat_Score))])   # Keep the sum of scores of all instances in a Bag (video)\n",
        "        \n",
        "        z1 = T.ones_like(Feat_Score)\n",
        "        z2 = T.concatenate([z1, Feat_Score])\n",
        "        z3 = T.concatenate([Feat_Score, z1])\n",
        "        z_22 = z2[31:]\n",
        "        z_44 = z3[:33]\n",
        "        z = z_22 - z_44\n",
        "        z = z[1:32]\n",
        "        z = T.sum(T.sqr(z))\n",
        "        sub_l2 = T.concatenate([sub_l2, T.stack(z)])\n",
        "\n",
        "    # sub_max[Num_d:] means include all elements after Num_d.\n",
        "    # AllLabels =[2 , 4, 3 ,9 ,6 ,12,7 ,18 ,9 ,14]\n",
        "    # z=x[4:]\n",
        "    #[  6.  12.   7.  18.   9.  14.]\n",
        "\n",
        "    sub_score = sub_max[Num_d:]  # We need this step since we have used T.ones_like\n",
        "    F_labels = sub_sum_labels[Num_d:] # We need this step since we have used T.ones_like\n",
        "    #  F_labels contains integer 32 for normal video and 0 for abnormal videos. This because of labeling done at the end of \"load_dataset_Train_batch\"\n",
        "\n",
        "\n",
        "\n",
        "    # AllLabels =[2 , 4, 3 ,9 ,6 ,12,7 ,18 ,9 ,14]\n",
        "    # z=x[:4]\n",
        "    # [ 2 4 3 9]... This shows 0 to 3 elements\n",
        "\n",
        "    sub_sum_l1 = sub_sum_l1[Num_d:] # We need this step since we have used T.ones_like\n",
        "    sub_sum_l1 = sub_sum_l1[:n_exp]\n",
        "    sub_l2 = sub_l2[Num_d:]         # We need this step since we have used T.ones_like\n",
        "    sub_l2 = sub_l2[:n_exp]\n",
        "\n",
        "\n",
        "    indx_nor = theano.tensor.eq(F_labels, 32).nonzero()[0]  # Index of normal videos: Since we labeled 1 for each of 32 segments of normal videos F_labels=32 for normal video\n",
        "    indx_abn = theano.tensor.eq(F_labels, 0).nonzero()[0]\n",
        "\n",
        "    n_Nor=n_exp\n",
        "\n",
        "    Sub_Nor = sub_score[indx_nor] # Maximum Score for each of abnormal video\n",
        "    Sub_Abn = sub_score[indx_abn] # Maximum Score for each of normal video\n",
        "\n",
        "    z = T.ones_like(y_true)\n",
        "    for ii in range(0, n_Nor, 1):\n",
        "        sub_z = T.maximum(1 - Sub_Abn + Sub_Nor[ii], 0) + T.maximum(0, Sub_Nor[ii] - T.log2(Sub_Abn))\n",
        "        z = T.concatenate([z, T.stack(T.sum(sub_z))])\n",
        "\n",
        "    z = z[Num_d:]  # We need this step since we have used T.ones_like\n",
        "    z = T.mean(z, axis=-1) +  0.00008*T.sum(sub_sum_l1) + 0.00008*T.sum(sub_l2)  # Final Loss f\n",
        "    \n",
        "    return z # this is y_predicted tensor, the return of loss function\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cx9YwFb0dLZu",
        "colab_type": "text"
      },
      "source": [
        "# Training code\n",
        "**Train on batch, size of 60, save model's weight after each 1000 iterations.**\n",
        "\n",
        "\n",
        "1.   Input: specify video feature (txt file) directory (Normal and Abnormal); directory to save the weight;\n",
        "2.   Output: model's weight (*.mat file). In addition, plot the loss value in every batch after 20 iterations.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AFMGfLvcz_n",
        "colab_type": "code",
        "outputId": "c2379852-89b7-427d-88da-e064d8f0d664",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        }
      },
      "source": [
        "adagrad=Adagrad(lr=0.01, epsilon=1e-08)\n",
        "\n",
        "model.compile(loss=custom_objective, optimizer=adagrad)\n",
        "\n",
        "print(\"Starting training...\")\n",
        "\n",
        "AllClassPath='/content/gdrive/My Drive/Colab Notebooks/mydrive/Train_RoadAccidents/'\n",
        "# AllClassPath contains C3D features (.txt file)  of each video. Each text file contains 32 features, each of 4096 dimension\n",
        "output_dir='/content/gdrive/My Drive/Colab Notebooks/mydrive/Train_RoadAccidents/Result/Weight/'\n",
        "# Output_dir is the directory where you want to save trained weights\n",
        "\n",
        "loss_dir = '/content/gdrive/My Drive/Colab Notebooks/mydrive/Train_RoadAccidents/Result/Loss' # to save figure\n",
        "weights_path = output_dir + 'weights.mat'\n",
        "# weights.mat are the model weights that you will get after (or during) that training\n",
        "model_path = output_dir + 'model.json'\n",
        "\n",
        "if not os.path.exists(output_dir):\n",
        "       os.makedirs(output_dir)\n",
        "    \n",
        "if not os.path.exists(loss_dir):\n",
        "       os.makedirs(loss_dir)\n",
        "    \n",
        "All_class_files= listdir(AllClassPath)\n",
        "All_class_files.sort()\n",
        "loss_graph =[]\n",
        "num_iters = 10000\n",
        "total_iterations = 0\n",
        "batchsize=60\n",
        "time_before = datetime.now()\n",
        "\n",
        "for it_num in range(num_iters):\n",
        "\n",
        "    AbnormalPath = os.path.join(AllClassPath, All_class_files[0])  # Path of abnormal already computed C3D features\n",
        "    NormalPath = os.path.join(AllClassPath, All_class_files[1])    # Path of Normal already computed C3D features\n",
        "    inputs, targets=load_dataset_Train_batch(AbnormalPath, NormalPath)  # Load normal and abnormal video C3D features\n",
        "    # INPUTS: (1920x4096)\n",
        "    # Targets (1920,) (32*60 video)\n",
        "    # INPUT: \n",
        "    #   1/ A BATCH of 1920 feature vector (4096d) for each segment, 810 abnormal, 798 normal\n",
        "    #   2/ LABEL of 1920 segments, integer value 0/1 (regression)\n",
        "    \n",
        "    print(\"------------------- TRAIN ON BATCH- iteration \", it_num)\n",
        "    batch_loss =model.train_on_batch(inputs, targets)\n",
        "    loss_graph = np.hstack((loss_graph, batch_loss)) #put to stack of numpy array\n",
        "    total_iterations += 1\n",
        "    \n",
        "    # PLOT THE LOSS\n",
        "    plt.plot(loss_graph, label='loss')\n",
        "    plt.title('Loss')\n",
        "    plt.legend()\n",
        "    plt.xlabel('Number of iteration')\n",
        "    plt.ylabel('Loss')\n",
        "    \n",
        "    if total_iterations % 20 == 1:\n",
        "      plt.savefig(loss_dir + 'loss_' + str(total_iterations) +'.png')\n",
        "      print(\"These iteration=\" + str(total_iterations) + \") took: \" + str(datetime.now() - time_before) + \", with loss of \" + str(batch_loss))\n",
        "    plt.show()\n",
        "      \n",
        "    if total_iterations % 20 == 1:\n",
        "        iteration_path = output_dir + 'Iterations_graph_' + str(total_iterations) + '.mat'\n",
        "        savemat(iteration_path, dict(loss_graph=loss_graph))\n",
        "        clear_output()\n",
        "    if total_iterations % 1000 == 0:  # Save the model at every 1000th iterations.\n",
        "       weights_path = output_dir + 'weights_AllLoss2_L1L2_' + str(total_iterations) + '.mat'\n",
        "       save_model(model, model_path, weights_path)\n",
        "\n",
        "save_model(model, model_path, weights_path)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting training...\n",
            "Loading Abnormal videos Features...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-76439532e7ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mAbnormalPath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAllClassPath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAll_class_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Path of abnormal already computed C3D features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mNormalPath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAllClassPath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAll_class_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m# Path of Normal already computed C3D features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mload_dataset_Train_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAbnormalPath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNormalPath\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Load normal and abnormal video C3D features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0;31m# INPUTS: (1920x4096)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;31m# Targets (1920,) (32*60 video)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-faf83e76dbc2>\u001b[0m in \u001b[0;36mload_dataset_Train_batch\u001b[0;34m(AbnormalPath, NormalPath)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0miv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mAbnor_list_iter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mVideo_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVideo_count\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0mVideoPath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAllVideos_Path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAll_Videos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0miv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVideoPath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzuhdgpCgAbb",
        "colab_type": "text"
      },
      "source": [
        "# Testing\n",
        "**Predict the score for each segment within a video on Testing set**\n",
        "\n",
        "\n",
        "1.   Input: model's weight (*.mat file), specify the directory of testing video feauture (100 videos)\n",
        "2.   Output: .*mat file, each file corresponds to each video score. A video score is a vector of 32-d, each value is abnormal score of each video segments.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IUdmsLrmnem",
        "colab_type": "code",
        "outputId": "8876f216-fff4-44e9-8cbb-6b4c5d9e264f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "\n",
        "\n",
        "def load_model(json_path):  # Function to load the model\n",
        "    model = model_from_json(open(json_path).read())\n",
        "    return model\n",
        "\n",
        "def load_weights(model, weight_path):  # Function to load the model weights\n",
        "    dict2 = loadmat(weight_path)\n",
        "    dict = conv_dict(dict2)\n",
        "    i = 0\n",
        "    for layer in model.layers:\n",
        "        weights = dict[str(i)]\n",
        "        layer.set_weights(weights)\n",
        "        i += 1\n",
        "    return model\n",
        "\n",
        "def conv_dict(dict2):\n",
        "    i = 0\n",
        "    dict = {}\n",
        "    for i in range(len(dict2)):\n",
        "        if str(i) in dict2:\n",
        "            if dict2[str(i)].shape == (0, 0):\n",
        "                dict[str(i)] = dict2[str(i)]\n",
        "            else:\n",
        "                weights = dict2[str(i)][0]\n",
        "                weights2 = []\n",
        "                for weight in weights:\n",
        "                    if weight.shape in [(1, x) for x in range(0, 5000)]:\n",
        "                        weights2.append(weight[0])\n",
        "                    else:\n",
        "                        weights2.append(weight)\n",
        "                dict[str(i)] = weights2\n",
        "    return dict\n",
        "\n",
        "# Load Video\n",
        "\n",
        "def load_dataset_One_Video_Features(Test_Video_Path):\n",
        "\n",
        "    VideoPath =Test_Video_Path\n",
        "    f = open(VideoPath, \"r\")\n",
        "    words = f.read().split()\n",
        "    num_feat = int(len(words) / 4096)\n",
        "    # Number of features per video to be loaded. In our case num_feat=32, as we divide the video into 32 segments. Note that\n",
        "    # we have already computed C3D features for the whole video and divided the video features into 32 segments.\n",
        "\n",
        "    count = -1;\n",
        "    VideoFeatues = []\n",
        "    for feat in range(0, num_feat):\n",
        "        feat_row1 = np.float32(words[feat * 4096:feat * 4096 + 4096])\n",
        "        count = count + 1\n",
        "        if count == 0:\n",
        "            VideoFeatues = feat_row1\n",
        "        if count > 0:\n",
        "            VideoFeatues = np.vstack((VideoFeatues, feat_row1))\n",
        "    AllFeatures = VideoFeatues\n",
        "\n",
        "    return  AllFeatures\n",
        "\n",
        "\n",
        "\n",
        "print(\"Starting testing...\")\n",
        "\n",
        "\n",
        "AllTest_Video_Path = '/content/gdrive/My Drive/HumanBehaviors/C3D_Feature_txt/Test_RoadAccidents/'\n",
        "# AllTest_Video_Path contains C3D features (txt file)of each video.\n",
        "\n",
        "Results_Path = '/content/gdrive/My Drive/HumanBehaviors/Result/PredictedScore/'\n",
        "# Results_Path is the folder where you can save your results\n",
        "\n",
        "Model_dir='/content/gdrive/My Drive/HumanBehaviors/Result/Weight/'\n",
        "# Model_dir is the folder where we have placed our trained weights\n",
        "\n",
        "weights_path = Model_dir + 'weights_ALL_L1L2_10000.mat'\n",
        "# weights_path is Trained model weights\n",
        "\n",
        "model_path = Model_dir + 'model.json'\n",
        "\n",
        "if not os.path.exists(Results_Path):\n",
        "       os.makedirs(Results_Path)\n",
        "\n",
        "All_Test_files= listdir(AllTest_Video_Path)\n",
        "All_Test_files.sort()\n",
        "\n",
        "model=load_model(model_path)\n",
        "load_weights(model, weights_path)\n",
        "nVideos=len(All_Test_files)\n",
        "time_before = datetime.now()\n",
        "\n",
        "for iv in range(nVideos):\n",
        "\n",
        "    Test_Video_Path = os.path.join(AllTest_Video_Path, All_Test_files[iv])\n",
        "    inputs=load_dataset_One_Video_Features(Test_Video_Path) # 32 segments features for one testing video\n",
        "    predictions = model.predict_on_batch(inputs)   # Get anomaly prediction for each of 32 video segments.\n",
        "    aa=All_Test_files[iv]\n",
        "    aa=aa[0:-6]\n",
        "    A_predictions_path = Results_Path + aa + '.mat'  # Save array of 1*32, containing anomaly score for each segment. Please see Evaluate Anomaly Detector to compute  ROC.\n",
        "    savemat(A_predictions_path, dict(predictions = predictions))\n",
        "    print (A_predictions_path)\n",
        "    print (\"Total Time took: \" + str(datetime.now() - time_before))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-4ab29d6f8646>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Function to load the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'numpy' is not defined"
          ]
        }
      ]
    }
  ]
}